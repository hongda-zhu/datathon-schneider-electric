# ğŸ¤– LLM Implementation - Gemini 2.0-Flash

## âœ… æ˜¯çš„ï¼Œæœ‰ LLMï¼(Yes, there is LLM!)

**Model:** Google Gemini 2.0-Flash
**Status:** âœ… Active and working
**Cases with AI:** 15 opportunities (5% of test set)

---

## ğŸ“ åœ¨å“ªé‡Œï¼Ÿ(Where is it?)

### 1. Code Location (ä»£ç ä½ç½®)
File: `local_pipeline.py` (lines 543-663)

```python
# Line 543-663: GEMINI AI FOR INSIGHTS
gemini_key = os.environ.get("GEMINI_API_KEY")
if gemini_key:
    import google.generativeai as genai
    genai.configure(api_key=gemini_key)
    model_llm = genai.GenerativeModel('gemini-2.0-flash')
```

### 2. Configuration (é…ç½®)
File: `.env`
```
GEMINI_API_KEY=AIzaSyAGltKL6hvhZ9L3YHCqglSafDUz_YTTcR4
```

### 3. Output Files (è¾“å‡ºæ–‡ä»¶)
```
output/json/
â”œâ”€â”€ global_insights.json     # Global insights (LLM-enhanced)
â”œâ”€â”€ 13701.json              # Case with AI (ai_generated: true)
â”œâ”€â”€ 13982.json              # Case with AI
â”œâ”€â”€ 14992.json              # Case with AI
â”œâ”€â”€ 15435.json              # Case with AI
â””â”€â”€ ... (15 cases total with AI)
```

---

## ğŸ¯ æ€ä¹ˆç”¨çš„ï¼Ÿ(How does it work?)

### What the LLM Does:

#### 1. **Global Business Insights** (å…¨å±€æ´å¯Ÿ)
- Analyzes top 10 most important features
- Generates 5 business insights in business-friendly language
- Generates 5 actionable recommendations

**Input to LLM:**
```
Model performance: F1=0.837, AUC=0.922
Top features: opp_maturity, opp_age_squared, cust_hitrate...

Task: Generate 5 business insights and 5 recommendations
```

**LLM Output Example:**
```json
{
  "business_insights": [
    "Opportunity maturity and age are strong indicators...",
    "High customer hit rate is a positive signal..."
  ],
  "recommendations": [
    "Develop stricter qualification criteria for old opportunities...",
    "Invest in competitive intelligence..."
  ]
}
```

#### 2. **Case-Specific Action Plans** (ä¸ªæ¡ˆè¡ŒåŠ¨è®¡åˆ’)
For 15 sample opportunities, the LLM generates **3 specific next steps** based on SHAP values.

**Input to LLM:**
```
Opportunity ID: 13701
Win probability: 78.6%

Top positive factors:
- cust_hitrate: +0.264
- customer_activity: +0.195

Top negative factors:
- customer_engagement: -0.222
- product_A: -0.159

Task: Generate 3 actionable next steps
```

**LLM Output Example:**
```json
{
  "next_steps": [
    "Increase engagement with the customer beyond the current level to
     address the 'customer_engagement' negative factor",
    "Proactively propose alternative Schneider Electric products to
     decrease reliance on 'product_A'",
    "Leverage the positive 'iberia_engagement' by showcasing successful
     case studies from other Iberia customers"
  ]
}
```

---

## ğŸ” æ€ä¹ˆçœ‹ï¼Ÿ(How to view it?)

### Method 1: Dashboard (æ¨è)

```bash
streamlit run app_final.py
```

**Steps:**
1. Go to **Case Explorer**
2. Select one of these IDs (æœ‰AIçš„æ¡ˆä¾‹):
   - **13701** (Win 78.6% - High priority)
   - **14992** (Win 97.5% - Very high)
   - **3414** (Win 13.5% - Needs help)
   - **13982**, **15435**, **16232**, etc.

3. Scroll down to **"ğŸ¯ Recommended Action"**
4. You'll see AI-generated next steps like:
   ```
   Next Steps:
   1. Increase engagement with customer to address
      'customer_engagement' negative factor...
   2. Proactively propose alternative products...
   3. Leverage positive 'iberia_engagement'...
   ```

### Method 2: JSON Files (ç›´æ¥æŸ¥çœ‹)

```bash
# View AI-generated case
cat output/json/13701.json | jq '.business_recommendation'
```

**Look for:**
```json
{
  "ai_generated": true,  â† This means LLM was used
  "next_steps": [
    "Specific action based on SHAP values..."
  ]
}
```

### Method 3: Compare AI vs Non-AI

**Case WITH AI (æœ‰AI):**
```bash
cat output/json/13701.json | jq '.business_recommendation.next_steps'
```
Output:
```
"Increase engagement... addressing 'customer_engagement' -0.22 impact"
```

**Case WITHOUT AI (æ²¡æœ‰AI):**
```bash
cat output/json/102.json | jq '.business_recommendation.next_steps'
```
Output:
```
"Leverage existing engagement"  â† Generic rule
```

---

## ğŸ“Š Statistics (ç»Ÿè®¡)

```
Total test cases:        7,180
With JSON analysis:        300
With AI recommendations:    15 (5%)
Without AI:                285 (95% - use simple rules)
```

**Why only 15?**
- API quota limit: 15 requests/minute (free tier)
- Script generates AI for sample cases (first 5 + middle 5 + last 5)

---

## ğŸ§ª Verify It's Working (éªŒè¯æ–¹æ³•)

### Quick Test:
```bash
# Check if LLM generated insights
cat output/json/global_insights.json | jq '.business_insights[0]'
```

Expected output (LLM-generated):
```
"Opportunity maturity and age are strong indicators, suggesting
timing and deal progression are critical factors..."
```

### Dashboard Test:
```bash
streamlit run app_final.py
```

1. **Global Insights** page â†’ See business insights (LLM-enhanced)
2. **Case Explorer** â†’ ID 13701 â†’ See AI-generated next steps

---

## ğŸ¯ Key Difference: AI vs Rules

| Feature | Without AI (è§„åˆ™) | With AI (LLM) |
|---------|-------------------|---------------|
| **Next Steps** | Generic templates | Specific to SHAP values |
| **Example** | "Leverage existing engagement" | "Increase engagement to address -0.22 impact of customer_engagement" |
| **Context** | None | References actual SHAP factors |
| **Language** | Simple | Business-friendly explanations |

---

## âœ… Summary (æ€»ç»“)

**æ˜¯çš„ï¼ŒLLM åœ¨è¿è¡Œï¼**

- âœ… Using: Google Gemini 2.0-Flash
- âœ… Location: `local_pipeline.py` lines 543-663
- âœ… API Key: Configured in `.env`
- âœ… Output: 15 cases with AI-generated recommendations
- âœ… Visible in: Dashboard (Case Explorer) and JSON files

**View in dashboard:**
```bash
streamlit run app_final.py
# Go to Case Explorer â†’ Select ID 13701
# See AI-generated "Next Steps" in ğŸ¯ Recommended Action
```
